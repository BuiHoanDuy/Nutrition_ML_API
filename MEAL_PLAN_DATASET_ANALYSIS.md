# BÃO CÃO PHÃ‚N TÃCH DATASET_THUCDON.CSV VÃ€ LUá»’NG Xá»¬ LÃ MEAL PLAN

## ğŸ“‹ Má»¤C Lá»¤C

1. [Tá»•ng quan Dataset](#1-tá»•ng-quan-dataset)
2. [Cáº¥u trÃºc dá»¯ liá»‡u](#2-cáº¥u-trÃºc-dá»¯-liá»‡u)
3. [PhÃ¢n tÃ­ch chi tiáº¿t](#3-phÃ¢n-tÃ­ch-chi-tiáº¿t)
4. [Luá»“ng Training Model](#4-luá»“ng-training-model)
5. [Luá»“ng Inference (Gá»£i Ã½ thá»±c Ä‘Æ¡n)](#5-luá»“ng-inference-gá»£i-Ã½-thá»±c-Ä‘Æ¡n)
6. [CÃ´ng nghá»‡ vÃ  Thuáº­t toÃ¡n](#6-cÃ´ng-nghá»‡-vÃ -thuáº­t-toÃ¡n)
7. [Äiá»ƒm máº¡nh vÃ  Háº¡n cháº¿](#7-Ä‘iá»ƒm-máº¡nh-vÃ -háº¡n-cháº¿)

---

## 1. Tá»”NG QUAN DATASET

### 1.1. ThÃ´ng tin cÆ¡ báº£n

- **TÃªn file**: `Dataset_Thucdon.csv`
- **Sá»‘ lÆ°á»£ng máº«u**: ~2,347 thá»±c Ä‘Æ¡n (2,348 dÃ²ng bao gá»“m header)
- **Má»¥c Ä‘Ã­ch**: Dataset thá»±c Ä‘Æ¡n dinh dÆ°á»¡ng Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a theo tÃ¬nh tráº¡ng sá»©c khá»e vÃ  má»¥c tiÃªu
- **Äá»‹nh dáº¡ng**: CSV, encoding UTF-8

### 1.2. Äáº·c Ä‘iá»ƒm ná»•i báº­t

âœ… **Äa dáº¡ng**: Bao gá»“m cáº£ cháº¿ Ä‘á»™ Äƒn chay vÃ  khÃ´ng chay  
âœ… **CÃ¡ nhÃ¢n hÃ³a**: Má»—i thá»±c Ä‘Æ¡n Ä‘Æ°á»£c thiáº¿t káº¿ cho tÃ¬nh tráº¡ng sá»©c khá»e cá»¥ thá»ƒ  
âœ… **Äáº§y Ä‘á»§**: CÃ³ Ä‘á»§ 4 bá»¯a: sÃ¡ng, trÆ°a, tá»‘i, phá»¥  
âœ… **Thá»±c táº¿**: MÃ³n Äƒn Viá»‡t Nam phá»• biáº¿n, dá»… thá»±c hiá»‡n  

---

## 2. Cáº¤U TRÃšC Dá»® LIá»†U

### 2.1. CÃ¡c cá»™t trong dataset

| Cá»™t | Kiá»ƒu dá»¯ liá»‡u | MÃ´ táº£ | VÃ­ dá»¥ |
|-----|--------------|-------|-------|
| **Bá»¯a sÃ¡ng** | String | MÃ³n Äƒn bá»¯a sÃ¡ng | "Khoai lang háº¥p" |
| **Bá»¯a trÆ°a** | String | MÃ³n Äƒn bá»¯a trÆ°a | "Canh gÃ  lÃ¡ giang; Miáº¿n; TrÃ¡i cÃ¢y Ã­t Ä‘Æ°á»ng" |
| **Bá»¯a tá»‘i** | String | MÃ³n Äƒn bá»¯a tá»‘i | "Phá»Ÿ bÃ²; Rau luá»™c; CÆ¡m tráº¯ng Ã­t" |
| **Bá»¯a phá»¥** | String | MÃ³n Äƒn bá»¯a phá»¥ | "Háº¡t háº¡nh nhÃ¢n" |
| **Cháº¿ Ä‘á»™ Äƒn** | String | Cháº¿ Ä‘á»™ Äƒn uá»‘ng | "KhÃ´ng chay", "chay" |
| **TÃ¬nh tráº¡ng sá»©c khá»e** | String | CÃ¡c váº¥n Ä‘á» sá»©c khá»e (nhiá»u giÃ¡ trá»‹) | "Tim máº¡ch, Suy dinh dÆ°á»¡ng, Thiáº¿u káº½m, Tiá»ƒu Ä‘Æ°á»ng" |
| **Má»¥c tiÃªu** | String | Má»¥c tiÃªu dinh dÆ°á»¡ng (nhiá»u giÃ¡ trá»‹) | "Giáº£m muá»‘i, á»•n Ä‘á»‹nh huyáº¿t Ã¡p, Giáº£m má»¡ bÃ£o hÃ²a..." |
| **TÃ¡o bÃ³n** | Binary (0/1) | CÃ³ bá»‹ tÃ¡o bÃ³n khÃ´ng | 0 hoáº·c 1 |
| **BÃ©o phÃ¬** | Binary (0/1) | CÃ³ bá»‹ bÃ©o phÃ¬ khÃ´ng | 0 hoáº·c 1 |
| **Tim máº¡ch** | Binary (0/1) | CÃ³ váº¥n Ä‘á» tim máº¡ch khÃ´ng | 0 hoáº·c 1 |
| **Má»¡ trong mÃ¡u** | Binary (0/1) | CÃ³ má»¡ trong mÃ¡u khÃ´ng | 0 hoáº·c 1 |
| **Huyáº¿t Ã¡p** | Binary (0/1) | CÃ³ váº¥n Ä‘á» huyáº¿t Ã¡p khÃ´ng | 0 hoáº·c 1 |
| **Thiáº¿u mÃ¡u** | Binary (0/1) | CÃ³ thiáº¿u mÃ¡u khÃ´ng | 0 hoáº·c 1 |
| **Thiáº¿u káº½m** | Binary (0/1) | CÃ³ thiáº¿u káº½m khÃ´ng | 0 hoáº·c 1 |
| **Thiáº¿u canxi** | Binary (0/1) | CÃ³ thiáº¿u canxi khÃ´ng | 0 hoáº·c 1 |
| **Suy dinh dÆ°á»¡ng** | Binary (0/1) | CÃ³ suy dinh dÆ°á»¡ng khÃ´ng | 0 hoáº·c 1 |
| **Tiá»ƒu Ä‘Æ°á»ng** | Binary (0/1) | CÃ³ tiá»ƒu Ä‘Æ°á»ng khÃ´ng | 0 hoáº·c 1 |

### 2.2. Cáº¥u trÃºc dá»¯ liá»‡u Ä‘áº·c biá»‡t

- **TÃ¬nh tráº¡ng sá»©c khá»e**: CÃ³ thá»ƒ chá»©a nhiá»u giÃ¡ trá»‹, phÃ¢n cÃ¡ch báº±ng dáº¥u pháº©y
- **Má»¥c tiÃªu**: CÃ³ thá»ƒ chá»©a nhiá»u má»¥c tiÃªu, phÃ¢n cÃ¡ch báº±ng dáº¥u pháº©y
- **MÃ³n Äƒn**: CÃ³ thá»ƒ chá»©a nhiá»u mÃ³n trong 1 bá»¯a, phÃ¢n cÃ¡ch báº±ng dáº¥u cháº¥m pháº©y (`;`)

### 2.3. VÃ­ dá»¥ dá»¯ liá»‡u

```csv
Bá»¯a sÃ¡ng,Bá»¯a phá»¥,Bá»¯a trÆ°a,Bá»¯a tá»‘i,Cháº¿ Ä‘á»™ Äƒn,...,TÃ¬nh tráº¡ng sá»©c khá»e,Má»¥c tiÃªu
Khoai lang háº¥p,Háº¡t háº¡nh nhÃ¢n,Canh gÃ  lÃ¡ giang; Miáº¿n; TrÃ¡i cÃ¢y Ã­t Ä‘Æ°á»ng,Phá»Ÿ bÃ²; Rau luá»™c; CÆ¡m tráº¯ng Ã­t,KhÃ´ng chay,...,"Tim máº¡ch, Suy dinh dÆ°á»¡ng, Thiáº¿u káº½m, Tiá»ƒu Ä‘Æ°á»ng","Giáº£m muá»‘i, á»•n Ä‘á»‹nh huyáº¿t Ã¡p, Giáº£m má»¡ bÃ£o hÃ²a, tÄƒng cháº¥t xÆ¡, TÄƒng cÃ¢n, bá»• sung nÄƒng lÆ°á»£ng vÃ  Ä‘áº¡m, Bá»• sung káº½m vÃ  Ä‘áº¡m, á»”n Ä‘á»‹nh Ä‘Æ°á»ng huyáº¿t, TÄƒng cháº¥t xÆ¡ hÃ²a tan"
```

---

## 3. PHÃ‚N TÃCH CHI TIáº¾T

### 3.1. PhÃ¢n loáº¡i theo cháº¿ Ä‘á»™ Äƒn

- **KhÃ´ng chay**: Pháº§n lá»›n cÃ¡c thá»±c Ä‘Æ¡n
- **Chay**: Má»™t sá»‘ thá»±c Ä‘Æ¡n dÃ nh cho ngÆ°á»i Äƒn chay

### 3.2. PhÃ¢n loáº¡i theo tÃ¬nh tráº¡ng sá»©c khá»e

CÃ¡c tÃ¬nh tráº¡ng sá»©c khá»e phá»• biáº¿n trong dataset:

1. **Tim máº¡ch**: Thá»±c Ä‘Æ¡n giáº£m muá»‘i, giáº£m má»¡ bÃ£o hÃ²a
2. **BÃ©o phÃ¬**: Thá»±c Ä‘Æ¡n giáº£m cÃ¢n, kiá»ƒm soÃ¡t nÄƒng lÆ°á»£ng
3. **Tiá»ƒu Ä‘Æ°á»ng**: Thá»±c Ä‘Æ¡n á»•n Ä‘á»‹nh Ä‘Æ°á»ng huyáº¿t, tÄƒng cháº¥t xÆ¡
4. **Suy dinh dÆ°á»¡ng**: Thá»±c Ä‘Æ¡n tÄƒng cÃ¢n, bá»• sung nÄƒng lÆ°á»£ng vÃ  Ä‘áº¡m
5. **Thiáº¿u mÃ¡u**: Thá»±c Ä‘Æ¡n bá»• sung sáº¯t
6. **Thiáº¿u canxi**: Thá»±c Ä‘Æ¡n bá»• sung canxi vÃ  vitamin D
7. **Thiáº¿u káº½m**: Thá»±c Ä‘Æ¡n bá»• sung káº½m vÃ  Ä‘áº¡m
8. **Huyáº¿t Ã¡p**: Thá»±c Ä‘Æ¡n giáº£m muá»‘i, á»•n Ä‘á»‹nh huyáº¿t Ã¡p
9. **Má»¡ trong mÃ¡u**: Thá»±c Ä‘Æ¡n giáº£m má»¡ bÃ£o hÃ²a, tÄƒng cháº¥t xÆ¡
10. **TÃ¡o bÃ³n**: Thá»±c Ä‘Æ¡n tÄƒng cháº¥t xÆ¡, uá»‘ng Ä‘á»§ nÆ°á»›c

### 3.3. PhÃ¢n loáº¡i theo má»¥c tiÃªu

CÃ¡c má»¥c tiÃªu dinh dÆ°á»¡ng phá»• biáº¿n:

- **Giáº£m cÃ¢n**: Kiá»ƒm soÃ¡t nÄƒng lÆ°á»£ng, háº¡n cháº¿ cháº¥t bÃ©o xáº¥u
- **TÄƒng cÃ¢n**: Bá»• sung nÄƒng lÆ°á»£ng vÃ  Ä‘áº¡m
- **á»”n Ä‘á»‹nh Ä‘Æ°á»ng huyáº¿t**: Cho ngÆ°á»i tiá»ƒu Ä‘Æ°á»ng
- **Giáº£m muá»‘i**: Cho ngÆ°á»i tim máº¡ch, huyáº¿t Ã¡p
- **Bá»• sung vi cháº¥t**: Sáº¯t, canxi, káº½m
- **TÄƒng cháº¥t xÆ¡**: Cho tÃ¡o bÃ³n, tiá»ƒu Ä‘Æ°á»ng

### 3.4. Äáº·c Ä‘iá»ƒm mÃ³n Äƒn

- **Äa dáº¡ng**: Tá»« mÃ³n Ä‘Æ¡n giáº£n (khoai lang háº¥p) Ä‘áº¿n mÃ³n phá»©c táº¡p (phá»Ÿ bÃ², bÃ¡nh xÃ¨o)
- **Thá»±c táº¿**: MÃ³n Äƒn Viá»‡t Nam quen thuá»™c, dá»… tÃ¬m nguyÃªn liá»‡u
- **CÃ¢n báº±ng**: Má»—i bá»¯a thÆ°á»ng cÃ³ Ä‘á»§ tinh bá»™t, Ä‘áº¡m, rau cá»§

---

## 4. LUá»’NG TRAINING MODEL

### 4.1. Tá»•ng quan

File: `scripts/train_meal_plan_model.py`

### 4.2. CÃ¡c bÆ°á»›c xá»­ lÃ½

#### **BÆ°á»›c 1: Load dá»¯ liá»‡u**

```python
meal_plans_df = pd.read_csv('data/Dataset_Thucdon.csv', encoding='utf-8')
```

- Äá»c file CSV vá»›i encoding UTF-8
- Káº¿t quáº£: DataFrame vá»›i ~2,347 thá»±c Ä‘Æ¡n

#### **BÆ°á»›c 2: Chuáº©n hÃ³a tÃªn cá»™t**

```python
meal_plans_df = meal_plans_df.rename(columns={
    'Cháº¿ Ä‘á»™ Äƒn': 'che_do_an',
    'TÃ¬nh tráº¡ng sá»©c khá»e': 'tinh_trang_suc_khoe',
    'Má»¥c tiÃªu': 'muc_tieu',
    'Bá»¯a sÃ¡ng': 'bua_sang',
    'Bá»¯a trÆ°a': 'bua_trua',
    'Bá»¯a tá»‘i': 'bua_toi',
    'Bá»¯a phá»¥': 'bua_phu'
})
```

- Chuyá»ƒn tÃªn cá»™t tá»« tiáº¿ng Viá»‡t cÃ³ dáº¥u sang khÃ´ng dáº¥u, snake_case
- Má»¥c Ä‘Ã­ch: Dá»… xá»­ lÃ½ trong code, trÃ¡nh lá»—i encoding

#### **BÆ°á»›c 3: LÃ m sáº¡ch dá»¯ liá»‡u**

```python
# Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
for col in ['che_do_an', 'tinh_trang_suc_khoe', 'muc_tieu']:
    meal_plans_df[col] = meal_plans_df[col].str.strip()

# Xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u
meal_plans_df[user_features] = meal_plans_df[user_features].fillna('khÃ´ng cÃ³')
```

- Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
- Äiá»n giÃ¡ trá»‹ thiáº¿u báº±ng "khÃ´ng cÃ³"

#### **BÆ°á»›c 4: One-Hot Encoding cho User Features**

```python
user_features = ['tinh_trang_suc_khoe', 'muc_tieu', 'che_do_an']
encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)
user_features_encoded = encoder.fit_transform(meal_plans_df[user_features])
```

- MÃ£ hÃ³a cÃ¡c Ä‘áº·c trÆ°ng ngÆ°á»i dÃ¹ng (tÃ¬nh tráº¡ng sá»©c khá»e, má»¥c tiÃªu, cháº¿ Ä‘á»™ Äƒn)
- Káº¿t quáº£: Ma tráº­n sparse one-hot encoding
- LÆ°u encoder Ä‘á»ƒ dÃ¹ng trong inference

#### **BÆ°á»›c 5: Táº¡o embedding text cho PhoBERT**

```python
# Káº¿t há»£p táº¥t cáº£ cÃ¡c bá»¯a Äƒn
meal_plans_df['full_meal_plan'] = meal_plans_df[meal_cols].fillna('').apply(
    lambda row: ' '.join(row), axis=1
)

# Táº¡o text embedding bao gá»“m context
meal_plans_df['embedding_text'] = (
    meal_plans_df['che_do_an'] + ' ' +
    meal_plans_df['tinh_trang_suc_khoe'] + ' ' +
    meal_plans_df['muc_tieu'] + ' ' +
    meal_plans_df['full_meal_plan']
)
```

- Káº¿t há»£p ná»™i dung cÃ¡c bá»¯a Äƒn thÃ nh 1 chuá»—i
- ThÃªm context (cháº¿ Ä‘á»™ Äƒn, tÃ¬nh tráº¡ng sá»©c khá»e, má»¥c tiÃªu) vÃ o embedding text
- Má»¥c Ä‘Ã­ch: Táº¡o embedding phong phÃº, cÃ³ ngá»¯ cáº£nh

#### **BÆ°á»›c 6: Sinh PhoBERT Embeddings**

```python
phobert_model = AutoModel.from_pretrained("vinai/phobert-base")
tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")

def get_phobert_embeddings(texts, batch_size=32):
    # Tokenize
    inputs = tokenizer(texts, padding=True, truncation=True, 
                      return_tensors="pt", max_length=256)
    # Forward pass
    with torch.no_grad():
        outputs = phobert_model(**inputs)
    # Mean pooling
    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()
    return embeddings

meal_features_phobert = get_phobert_embeddings(meal_plan_texts)
```

- Load model PhoBERT (vinai/phobert-base) - mÃ´ hÃ¬nh BERT cho tiáº¿ng Viá»‡t
- Tokenize vÃ  táº¡o embedding cho má»—i thá»±c Ä‘Æ¡n
- Mean pooling: Láº¥y trung bÃ¬nh cá»§a cÃ¡c token embeddings
- Káº¿t quáº£: Ma tráº­n embedding (N x 768) vá»›i N = sá»‘ thá»±c Ä‘Æ¡n

#### **BÆ°á»›c 7: LÆ°u artifacts**

```python
# LÆ°u DataFrame Ä‘Ã£ xá»­ lÃ½
output_df.to_csv(model_dir / "meal_plans_data.csv", ...)

# LÆ°u encoder
joblib.dump(encoder, model_dir / "user_feature_encoder.pkl")

# LÆ°u PhoBERT model vÃ  tokenizer
phobert_model.save_pretrained(model_dir / "phobert_model")
tokenizer.save_pretrained(model_dir / "phobert_tokenizer")

# LÆ°u ma tráº­n embedding
scipy.sparse.save_npz(model_dir / "user_features_encoded.npz", ...)
np.save(model_dir / "meal_features_phobert.npy", meal_features_phobert)
```

**Artifacts Ä‘Æ°á»£c lÆ°u:**

1. `meal_plans_data.csv`: Dataset Ä‘Ã£ xá»­ lÃ½
2. `user_feature_encoder.pkl`: OneHotEncoder Ä‘Ã£ fit
3. `phobert_model/`: PhoBERT model Ä‘Ã£ lÆ°u
4. `phobert_tokenizer/`: Tokenizer Ä‘Ã£ lÆ°u
5. `user_features_encoded.npz`: Ma tráº­n one-hot encoding (sparse)
6. `meal_features_phobert.npy`: Ma tráº­n PhoBERT embeddings (dense)

---

## 5. LUá»’NG INFERENCE (Gá»¢I Ã THá»°C ÄÆ N)

### 5.1. Tá»•ng quan

File: `services/meal_plan_inference.py`

### 5.2. SÆ¡ Ä‘á»“ luá»“ng xá»­ lÃ½

```
User Question
    â†“
[1. Parse & Normalize]
    â†“
[2. Extract Keywords]
    â†“
[3. Filter Dataset]
    â†“
[4. PhoBERT Similarity]
    â†“
[5. Rank & Select]
    â†“
[6. Generate Response (Gemini)]
    â†“
Final Answer
```

### 5.3. Chi tiáº¿t tá»«ng bÆ°á»›c

#### **BÆ°á»›c 1: Parse vÃ  Normalize cÃ¢u há»i**

**HÃ m**: `parse_meal_plan_question(question: str)`

```python
# 1.1. Normalize + Fuzzy Correction
dict_corrected_base, normalized_question = normalize_user_question(
    question,
    keyword_maps=keyword_maps,
    vi_wordlist_tokens=vi_tokens,
    phrase_threshold=82,
    token_threshold=70
)
```

**Xá»­ lÃ½:**
- **Chuáº©n hÃ³a cÆ¡ báº£n**: Lowercase, bá» dáº¥u, xá»­ lÃ½ teencode
- **Fuzzy correction**: Sá»­a lá»—i chÃ­nh táº£ á»Ÿ má»©c phrase vÃ  token
- **Sá»­ dá»¥ng tá»« Ä‘iá»ƒn**: `keyword_maps.json` vÃ  `vietnamese_dict.txt`

**VÃ­ dá»¥:**
```
Input:  "TÃ´i muá»‘n thá»±c Ä‘Æ¡n eat clean Ä‘á»ƒ giáº£m cÃ¢n"
Output: "toi muon thuc don eat clean de giam can"
```

#### **BÆ°á»›c 2: Extract Keywords**

**HÃ m**: `_parse_question_with_keywords(question_lower: str)`

```python
parsed_params = {
    "health_status": "khÃ´ng cÃ³",      # TÃ¬nh tráº¡ng sá»©c khá»e
    "goal": "giáº£m cÃ¢n",                # Má»¥c tiÃªu
    "diet_type": "eat clean",          # Cháº¿ Ä‘á»™ Äƒn
    "requested_meals": ["Bá»¯a sÃ¡ng", "Bá»¯a trÆ°a", "Bá»¯a tá»‘i", "Bá»¯a phá»¥"]
}
```

**Xá»­ lÃ½:**
- TÃ¬m kiáº¿m keywords trong `keyword_maps.json`:
  - `health_status_map`: Tim máº¡ch, Tiá»ƒu Ä‘Æ°á»ng, BÃ©o phÃ¬...
  - `goal_map`: Giáº£m cÃ¢n, TÄƒng cÃ¢n, á»”n Ä‘á»‹nh Ä‘Æ°á»ng huyáº¿t...
  - `diet_type_map`: Eat clean, Chay, KhÃ´ng chay...
  - `meal_map`: Bá»¯a sÃ¡ng, Bá»¯a trÆ°a, Bá»¯a tá»‘i, Bá»¯a phá»¥
- Há»— trá»£ nhiá»u giÃ¡ trá»‹ (vÃ­ dá»¥: "Tim máº¡ch, Tiá»ƒu Ä‘Æ°á»ng")

#### **BÆ°á»›c 3: Filter Dataset**

**HÃ m**: `recommend_meal_plan(original_question, parsed_params)`

**Logic lá»c:**

```python
# 3.1. Kiá»ƒm tra cÃ³ keywords khÃ´ng
has_any_keyword = any(
    v and v != 'khÃ´ng cÃ³'
    for v in (health_status, goal, diet_type)
)

if has_any_keyword:
    # 3.2. Lá»c theo cháº¿ Ä‘á»™ Äƒn
    if diet_type != 'khÃ´ng cÃ³':
        conditions.append(
            filtered_df['Cháº¿ Ä‘á»™ Äƒn'].str.lower() == diet_type.lower()
        )
    
    # 3.3. Lá»c theo tÃ¬nh tráº¡ng sá»©c khá»e (há»— trá»£ nhiá»u giÃ¡ trá»‹)
    if health_status != 'khÃ´ng cÃ³':
        health_keywords = health_status.split(',')
        for kw in health_keywords:
            health_condition = health_condition | col.str.contains(kw)
        conditions.append(health_condition)
    
    # 3.4. Lá»c theo má»¥c tiÃªu (há»— trá»£ nhiá»u giÃ¡ trá»‹)
    if goal != 'khÃ´ng cÃ³':
        goal_keywords = goal.split(',')
        for kw in goal_keywords:
            goal_condition = goal_condition | col.str.contains(kw)
        conditions.append(goal_condition)
    
    # 3.5. Ãp dá»¥ng táº¥t cáº£ Ä‘iá»u kiá»‡n (AND logic)
    filtered_df = filtered_df[np.logical_and.reduce(conditions)]
```

**Káº¿t quáº£**: DataFrame Ä‘Ã£ Ä‘Æ°á»£c lá»c theo tiÃªu chÃ­ ngÆ°á»i dÃ¹ng

#### **BÆ°á»›c 4: PhoBERT Similarity Ranking**

```python
# 4.1. Táº¡o embedding cho cÃ¢u há»i
query_embedding = _get_query_embedding(
    query_text_for_embedding, 
    recommender.phobert_model, 
    recommender.phobert_tokenizer
)

# 4.2. TÃ­nh cosine similarity vá»›i cÃ¡c thá»±c Ä‘Æ¡n Ä‘Ã£ lá»c
similarity_scores = cosine_similarity(
    query_embedding, 
    filtered_embeddings
).flatten()

# 4.3. Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
top_indices = similarity_scores.argsort()[::-1]

# 4.4. Kiá»ƒm tra threshold
if best_score < SIMILARITY_THRESHOLD:  # 0.5
    # Thá»­ láº¡i vá»›i structured query
    query_text = "TÃ¬nh tráº¡ng sá»©c khá»e: ... | Má»¥c tiÃªu: ..."
    # Hoáº·c tráº£ vá» []
```

**Xá»­ lÃ½:**
- Táº¡o embedding cho cÃ¢u há»i báº±ng PhoBERT
- TÃ­nh cosine similarity vá»›i embeddings cá»§a cÃ¡c thá»±c Ä‘Æ¡n Ä‘Ã£ lá»c
- Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giáº£m dáº§n
- Náº¿u similarity < 0.5, thá»­ láº¡i vá»›i structured query hoáº·c tráº£ vá» []

#### **BÆ°á»›c 5: Rank & Select**

```python
# 5.1. Láº¥y top candidates
original_relevant_indices = [filtered_indices[i] for i in top_indices]

# 5.2. Xá»­ lÃ½ cache (Ä‘á»ƒ trÃ¡nh tráº£ vá» cÃ¹ng 1 káº¿t quáº£ nhiá»u láº§n)
if original_question in recommender.last_recommendation_cache:
    # Láº¥y káº¿t quáº£ tiáº¿p theo
    last_shown_index = recommender.last_recommendation_cache[original_question]
    next_pos = (current_pos + 1) % len(original_relevant_indices)
    best_match_index = original_relevant_indices[next_pos]
else:
    # Láº¥y káº¿t quáº£ Ä‘áº§u tiÃªn
    best_match_index = original_relevant_indices[0]

# 5.3. LÆ°u vÃ o cache
recommender.last_recommendation_cache[original_question] = best_match_index
```

**TÃ­nh nÄƒng Ä‘áº·c biá»‡t:**
- **Cache mechanism**: TrÃ¡nh tráº£ vá» cÃ¹ng 1 thá»±c Ä‘Æ¡n nhiá»u láº§n
- **Rotation**: Má»—i láº§n há»i láº¡i sáº½ tráº£ vá» thá»±c Ä‘Æ¡n khÃ¡c (náº¿u cÃ³)

#### **BÆ°á»›c 6: Generate Natural Response (Gemini)**

**HÃ m**: `generate_natural_response_from_recommendations()`

```python
# 6.1. Táº¡o prompt cho Gemini
prompt = f"""Báº¡n lÃ  má»™t chuyÃªn gia dinh dÆ°á»¡ng AI...
NgÆ°á»i dÃ¹ng há»i: "{question}"
{health_goal_context}

Dá»±a trÃªn dá»¯ liá»‡u, Ä‘Ã¢y lÃ  gá»£i Ã½ thá»±c Ä‘Æ¡n:
{recs_str}

YÃªu cáº§u:
1. Chá»‰ diá»…n giáº£i láº¡i thá»±c Ä‘Æ¡n, GIá»® NGUYÃŠN tÃªn mÃ³n Äƒn
2. Viáº¿t Má»˜T Ä‘oáº¡n vÄƒn ngáº¯n (3â€“5 cÃ¢u), thÃ¢n thiá»‡n
"""

# 6.2. Gá»i Gemini API
natural_response = await _call_gemini_llm(prompt=prompt, json_mode=False)

# 6.3. Xá»­ lÃ½ response
return natural_response.replace("\n", " ").strip()
```

**Xá»­ lÃ½:**
- Táº¡o prompt chi tiáº¿t vá»›i context vá» sá»©c khá»e vÃ  má»¥c tiÃªu
- Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn
- Xá»­ lÃ½ vÃ  lÃ m sáº¡ch response

### 5.4. CÃ¡c trÆ°á»ng há»£p Ä‘áº·c biá»‡t

#### **TrÆ°á»ng há»£p 1: CÃ³ keywords (health/goal/diet)**

```
Input: "TÃ´i muá»‘n thá»±c Ä‘Æ¡n eat clean Ä‘á»ƒ giáº£m cÃ¢n"
  â†“
Extract: goal="giáº£m cÃ¢n", diet_type="eat clean"
  â†“
Filter: Lá»c dataset theo goal vÃ  diet_type
  â†“
PhoBERT: TÃ­nh similarity, rank
  â†“
Select: Chá»n thá»±c Ä‘Æ¡n tá»‘t nháº¥t
  â†“
Gemini: Táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn
```

#### **TrÆ°á»ng há»£p 2: Generic meal query (khÃ´ng cÃ³ keywords)**

```
Input: "Thá»±c Ä‘Æ¡n hÃ´m nay lÃ  gÃ¬?"
  â†“
Detect: Generic meal query
  â†“
Filter: Lá»c thá»±c Ä‘Æ¡n "bÃ¬nh thÆ°á»ng" hoáº·c random
  â†“
Select: Chá»n ngáº«u nhiÃªn 1 thá»±c Ä‘Æ¡n an toÃ n
  â†“
Gemini: Táº¡o cÃ¢u tráº£ lá»i
```

#### **TrÆ°á»ng há»£p 3: KhÃ´ng cÃ³ keywords vÃ  khÃ´ng pháº£i generic query**

```
Input: "HÃ´m nay trá»i Ä‘áº¹p"
  â†“
Detect: KhÃ´ng pháº£i cÃ¢u há»i vá» dinh dÆ°á»¡ng
  â†“
Return: [] (empty)
  â†“
Gemini Fallback: Tráº£ lá»i chung chung hoáº·c tá»« chá»‘i
```

### 5.5. Fallback mechanism

```python
async def generate_answer_with_fallback(question, parsed_params, recommendations):
    # 1. Náº¿u cÃ³ recommendations tá»« data
    if recommendations:
        return await generate_natural_response_from_recommendations(...)
    
    # 2. Náº¿u khÃ´ng cÃ³ recommendations
    if has_any_keyword:
        # CÃ¢u há»i dinh dÆ°á»¡ng nhÆ°ng khÃ´ng cÃ³ data
        prompt = "Tá»± Ä‘á» xuáº¥t thá»±c Ä‘Æ¡n dá»±a trÃªn tÃ¬nh tráº¡ng..."
    else:
        # CÃ¢u há»i ngoÃ i lÄ©nh vá»±c dinh dÆ°á»¡ng
        prompt = "Tráº£ lá»i chung chung..."
    
    return await _call_gemini_llm(prompt)
```

---

## 6. CÃ”NG NGHá»† VÃ€ THUáº¬T TOÃN

### 6.1. CÃ´ng nghá»‡ sá»­ dá»¥ng

| CÃ´ng nghá»‡ | Má»¥c Ä‘Ã­ch | Version/Library |
|-----------|----------|-----------------|
| **Python** | NgÃ´n ngá»¯ chÃ­nh | 3.8+ |
| **pandas** | Xá»­ lÃ½ dá»¯ liá»‡u | - |
| **numpy** | TÃ­nh toÃ¡n sá»‘ há»c | - |
| **scikit-learn** | OneHotEncoder, cosine_similarity | - |
| **transformers** | PhoBERT model | Hugging Face |
| **torch** | Deep learning framework | PyTorch |
| **rapidfuzz** | Fuzzy string matching | - |
| **google.generativeai** | Gemini LLM API | - |
| **joblib** | Serialize models | - |
| **scipy** | Sparse matrix operations | - |

### 6.2. Thuáº­t toÃ¡n vÃ  MÃ´ hÃ¬nh

#### **6.2.1. One-Hot Encoding**

- **Má»¥c Ä‘Ã­ch**: MÃ£ hÃ³a cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n loáº¡i (tÃ¬nh tráº¡ng sá»©c khá»e, má»¥c tiÃªu, cháº¿ Ä‘á»™ Äƒn)
- **CÃ¡ch hoáº¡t Ä‘á»™ng**: Táº¡o vector binary cho má»—i giÃ¡ trá»‹ cÃ³ thá»ƒ
- **VÃ­ dá»¥**: 
  - "chay" â†’ [0, 1]
  - "KhÃ´ng chay" â†’ [1, 0]

#### **6.2.2. PhoBERT Embeddings**

- **Model**: `vinai/phobert-base`
- **Kiáº¿n trÃºc**: BERT-based, Ä‘Æ°á»£c fine-tune cho tiáº¿ng Viá»‡t
- **Input**: Text (cÃ¢u há»i hoáº·c mÃ´ táº£ thá»±c Ä‘Æ¡n)
- **Output**: Vector embedding 768 chiá»u
- **Pooling**: Mean pooling (trung bÃ¬nh cÃ¡c token embeddings)

**VÃ­ dá»¥ embedding text:**
```
"chay Tim máº¡ch, Tiá»ƒu Ä‘Æ°á»ng Giáº£m muá»‘i, á»•n Ä‘á»‹nh huyáº¿t Ã¡p Khoai lang háº¥p Háº¡t háº¡nh nhÃ¢n Canh gÃ  lÃ¡ giang; Miáº¿n; TrÃ¡i cÃ¢y Ã­t Ä‘Æ°á»ng Phá»Ÿ bÃ²; Rau luá»™c; CÆ¡m tráº¯ng Ã­t"
```

#### **6.2.3. Cosine Similarity**

- **CÃ´ng thá»©c**: `similarity = cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)`
- **Má»¥c Ä‘Ã­ch**: Äo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a embedding cÃ¢u há»i vÃ  embedding thá»±c Ä‘Æ¡n
- **Range**: [-1, 1], thÆ°á»ng dÃ¹ng [0, 1] cho embeddings
- **Threshold**: 0.5 (chá»‰ cháº¥p nháº­n similarity >= 0.5)

#### **6.2.4. Fuzzy String Matching**

- **Library**: `rapidfuzz`
- **Scorers**: 
  - `fuzz.ratio`: So sÃ¡nh toÃ n bá»™ chuá»—i
  - `fuzz.partial_ratio`: So sÃ¡nh pháº§n chuá»—i
  - `fuzz.token_sort_ratio`: So sÃ¡nh sau khi sáº¯p xáº¿p tokens
- **Má»¥c Ä‘Ã­ch**: Sá»­a lá»—i chÃ­nh táº£, xá»­ lÃ½ biáº¿n thá»ƒ tá»«

#### **6.2.5. Gemini LLM**

- **Model**: `gemini-2.5-flash` (hoáº·c configurable)
- **Má»¥c Ä‘Ã­ch**: Táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn tá»« structured data
- **Temperature**: 0.7 (cho natural language), 0.2 (cho JSON mode)
- **Safety settings**: Disabled (Ä‘á»ƒ cÃ³ control tá»‘t hÆ¡n)

### 6.3. Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING PIPELINE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dataset_Thucdon.csv
    â†“
[Data Cleaning & Normalization]
    â†“
[One-Hot Encoding] â†’ user_features_encoded.npz
    â†“
[PhoBERT Embedding] â†’ meal_features_phobert.npy
    â†“
[Save Artifacts]
    â”œâ”€â”€ meal_plans_data.csv
    â”œâ”€â”€ user_feature_encoder.pkl
    â”œâ”€â”€ phobert_model/
    â”œâ”€â”€ phobert_tokenizer/
    â”œâ”€â”€ user_features_encoded.npz
    â””â”€â”€ meal_features_phobert.npy

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INFERENCE PIPELINE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Question
    â†“
[Load Artifacts] (MealPlanRecommender.__init__)
    â†“
[Parse & Normalize] (parse_meal_plan_question)
    â”œâ”€â”€ normalize_user_question (fuzzy correction)
    â””â”€â”€ _parse_question_with_keywords (extract keywords)
    â†“
[Filter Dataset] (recommend_meal_plan)
    â”œâ”€â”€ Filter by diet_type
    â”œâ”€â”€ Filter by health_status
    â””â”€â”€ Filter by goal
    â†“
[PhoBERT Similarity] (recommend_meal_plan)
    â”œâ”€â”€ Generate query embedding
    â”œâ”€â”€ Calculate cosine similarity
    â””â”€â”€ Rank by similarity
    â†“
[Select Best Match] (recommend_meal_plan)
    â”œâ”€â”€ Check similarity threshold
    â””â”€â”€ Handle cache (rotation)
    â†“
[Generate Response] (generate_natural_response_from_recommendations)
    â”œâ”€â”€ Build prompt
    â”œâ”€â”€ Call Gemini API
    â””â”€â”€ Format response
    â†“
Final Answer
```

---

## 7. ÄIá»‚M Máº NH VÃ€ Háº N CHáº¾

### 7.1. Äiá»ƒm máº¡nh

âœ… **Dataset phong phÃº**: ~2,347 thá»±c Ä‘Æ¡n Ä‘a dáº¡ng  
âœ… **CÃ¡ nhÃ¢n hÃ³a tá»‘t**: Má»—i thá»±c Ä‘Æ¡n Ä‘Æ°á»£c thiáº¿t káº¿ cho tÃ¬nh tráº¡ng sá»©c khá»e cá»¥ thá»ƒ  
âœ… **Xá»­ lÃ½ tiáº¿ng Viá»‡t tá»‘t**: PhoBERT + fuzzy matching  
âœ… **Robust**: Nhiá»u fallback mechanisms  
âœ… **User-friendly**: Cache rotation, natural language response  
âœ… **Scalable**: CÃ³ thá»ƒ thÃªm thá»±c Ä‘Æ¡n má»›i vÃ o dataset  

### 7.2. Háº¡n cháº¿

âš ï¸ **Dataset cá»‘ Ä‘á»‹nh**: KhÃ´ng tá»± Ä‘á»™ng cáº­p nháº­t  
âš ï¸ **Thiáº¿u thÃ´ng tin dinh dÆ°á»¡ng chi tiáº¿t**: KhÃ´ng cÃ³ calorie, macro nutrients  
âš ï¸ **PhoBERT inference cháº­m**: Cáº§n optimize náº¿u scale lá»›n  
âš ï¸ **Phá»¥ thuá»™c Gemini API**: Cáº§n internet vÃ  API key  
âš ï¸ **Threshold cá»‘ Ä‘á»‹nh**: Similarity threshold = 0.5 cÃ³ thá»ƒ khÃ´ng phÃ¹ há»£p má»i trÆ°á»ng há»£p  

### 7.3. Khuyáº¿n nghá»‹ cáº£i thiá»‡n

1. **ThÃªm thÃ´ng tin dinh dÆ°á»¡ng**: Calorie, protein, carbs, fat cho má»—i thá»±c Ä‘Æ¡n
2. **A/B testing threshold**: Tá»‘i Æ°u similarity threshold
3. **Caching embeddings**: Cache query embeddings Ä‘á»ƒ tÄƒng tá»‘c
4. **Batch processing**: Xá»­ lÃ½ nhiá»u queries cÃ¹ng lÃºc
5. **Feedback loop**: Thu tháº­p feedback Ä‘á»ƒ cáº£i thiá»‡n recommendations

---

## 8. Káº¾T LUáº¬N

Há»‡ thá»‘ng Meal Plan Recommendation sá»­ dá»¥ng:

- **Dataset**: `Dataset_Thucdon.csv` vá»›i ~2,347 thá»±c Ä‘Æ¡n Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a
- **Training**: One-Hot Encoding + PhoBERT Embeddings
- **Inference**: Keyword parsing + Filtering + PhoBERT Similarity + Gemini LLM
- **CÃ´ng nghá»‡**: Python, scikit-learn, Transformers (PhoBERT), Gemini API

Há»‡ thá»‘ng cÃ³ kháº£ nÄƒng:
- Hiá»ƒu cÃ¢u há»i tiáº¿ng Viá»‡t tá»± nhiÃªn
- Lá»c vÃ  gá»£i Ã½ thá»±c Ä‘Æ¡n phÃ¹ há»£p vá»›i tÃ¬nh tráº¡ng sá»©c khá»e
- Táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn, thÃ¢n thiá»‡n

ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng recommendation system hoÃ n chá»‰nh, káº¿t há»£p rule-based filtering vÃ  semantic similarity Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p.



